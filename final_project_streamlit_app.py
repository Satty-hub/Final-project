# -*- coding: utf-8 -*-
"""Vaccine design from Code_final project_part.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12RuSrwgG1cao3FvU6InHVwadRanaiTZN
"""



!pip install pandas-profiling[notebook,html]
!pip install pycaret
!pip install sklearn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,classification_report,mean_squared_error,mean_absolute_error,confusion_matrix
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import ExtraTreesClassifier
from imblearn.over_sampling import SMOTE

import pandas as pd
import io
import requests

bcell_url = "https://drive.google.com/uc?id=1_v_AiVvwpSnuKCNplAimFS8sOlu-hZeQ&export=download"
covid_url = "https://drive.google.com/uc?id=13JRk-wG8GggBTA-3J1U4R5x3nhrT7KbY&export=download"
sars_url = "https://drive.google.com/uc?id=1hlza1PsXkHiBqzhpZpVKcLDlLUs4aQtj&export=download"
Tcell_url = "https://drive.google.com/uc?id=1wYhEDx7pRxiHzD58R2ihfDrSp5Bu68cc&export=download"

df_1 = pd.read_csv("https://drive.google.com/uc?id=1_v_AiVvwpSnuKCNplAimFS8sOlu-hZeQ&export=download" )   # bcells csv

df_2 = pd.read_csv ("https://drive.google.com/uc?id=1wYhEDx7pRxiHzD58R2ihfDrSp5Bu68cc&export=download")  # tcells csv
df_3 = pd.read_csv("https://drive.google.com/uc?id=1hlza1PsXkHiBqzhpZpVKcLDlLUs4aQtj&export=download" )  # sars csv
df_test = pd.read_csv("https://drive.google.com/uc?id=13JRk-wG8GggBTA-3J1U4R5x3nhrT7KbY&export=download") # covid csv

df_1.head()

df_2.head()

df_3.head()

df_test.head()

df_train = pd.concat ([df_1,df_3])

df_train.head()

df_train.isnull().sum()

df_test.head()

df_train.head()

"""**Data Overview**

**Data Preprocessing**
"""

def find_unique_length(df):
    list = []
    for i in df:
        if  len(i) not in list:
            list.append(len(i))
    return len(list)

find_unique_length((df_train["protein_seq"]))

len(df_train["protein_seq"].value_counts())

find_unique_length(df_train["parent_protein_id"])

len(df_train["parent_protein_id"].value_counts())

df_train.dtypes

df_train['protein_seq_length'] = df_train['protein_seq'].astype(str).map(len)
df_train['peptide_seq_length'] = df_train['peptide_seq'].astype(str).map(len)
df_train['parent_protein_id_length'] = df_train['parent_protein_id'].astype(str).map(len)

df_train['peptide_length']=df_train['end_position'] - df_train['start_position'] + 1

df_train.head()

"""# **Data Visualization**"""

num_vars=[x for x in df_train.columns if df_train[x].dtypes!='O']

!pip install plotly
import plotly.express as px # Import the plotly.express module and alias it as 'px'
num_vars=[x for x in df_train.columns if df_train[x].dtypes!='O']
for i in num_vars:
    fig=px.box(df_train, y=i, color='target')
    fig.show()

import matplotlib.pyplot as plt # Import matplotlib.pyplot and alias it as 'plt'
import seaborn as sns  # Import seaborn for statistical data visualization

fig, axes = plt.subplots(8, 2, figsize=(20, 20))
for i, j in enumerate(num_vars):
    ax = axes[int(i / 2), i % 2]
    sns.kdeplot(df_train[j], ax=ax)

df_train = df_train.drop(["parent_protein_id","protein_seq","peptide_seq","start_position","end_position"],axis =1)

df_train.head()

df_train = df_train.dropna(subset=['target'])

df_train.head()

"""# **Data Upscaling**"""

X = df_train.drop("target",axis = 1)
Y = df_train["target"]

from imblearn.over_sampling import SMOTE # Import the SMOTE class from imblearn.over_sampling
smote = SMOTE()
X, Y = smote.fit_resample(X, Y)

df_train = pd.concat([X,Y],axis = 1)

!pip install scikit-learn  # Install scikit-learn if not already installed
from sklearn.model_selection import train_test_split

train,test = train_test_split(df_train, test_size=0.1,random_state= 27)

"""# **Modal Comparison**"""

!pip install pycaret
from pycaret.classification import setup

experiment = setup(
    data = train,
    target = 'target',
    normalize = True
)

compare_models()

"""# **Data Notmalization**"""

X = MinMaxScaler().fit_transform(X)

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.25, random_state = 42)

print('Training Features Shape:', X_train.shape)
print('Training Labels Shape:', X_test.shape)
print('Testing Features Shape:', Y_train.shape)
print('Testing Labels Shape:', Y_test.shape)

"""# **Training Model**"""

rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)

rf.fit(X_train,Y_train)

# Convert X_test to a NumPy array with the same data type as X_train
X_test = X_test.values.astype(X_train.dtype)

# Now you can use X_test for prediction
Y_pred_rf = rf.predict(X_test)

"""# **generate_tcell_epitopes.py**"""

!pip install biopython

import pandas as pd
from Bio.SeqUtils.ProtParam import ProteinAnalysis
import random

# --- 1. Input your protein sequence here ---
spike_seq = (
    "MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHV"
    "SGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFL"
    "GVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINL"
    "VRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENG"
    "TITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWN"
    "RKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKL"
    "PDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYG"
    "FQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGR"
    "DIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPRWVYSTG"
    "SNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNN"
    "SIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEV"
    "FAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICA"
    "QKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLI"
    "ANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQID"
    "RLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHV"
    "TYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNT"
    "VYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYE"
    "QYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT"
)

# --- 2. Function to generate 9-mer peptides ---
def generate_peptides(sequence, length=9):
    return [(i + 1, i + length, sequence[i:i + length]) for i in range(len(sequence) - length + 1)]

# --- 3. Simulate immunological & biochemical features ---
def simulate_peptide_data(seq, parent_id="Spike_SARS_CoV_2"):
    peptides = generate_peptides(seq)
    rows = []
    for start, end, pep in peptides:
        analysis = ProteinAnalysis(pep)
        row = {
            "parent_protein_id": parent_id,
            "protein_seq": seq,
            "start_position": start,
            "end_position": end,
            "peptide_seq": pep,
            "chou_fasman": round(random.uniform(0.2, 1.0), 3),
            "emini": round(random.uniform(0.5, 2.5), 3),
            "kolaskar_tongaonkar": round(random.uniform(0.8, 1.2), 3),
            "parker": round(random.uniform(0.5, 3.0), 3),
            "isoelectric_point": round(analysis.isoelectric_point(), 2),
            "aromaticity": round(analysis.aromaticity(), 3),
            "hydrophobicity": round(analysis.gravy(), 3),
            "stability": round(analysis.instability_index(), 2)
        }
        rows.append(row)
    return pd.DataFrame(rows)

# --- 4. Generate the data and export as CSV ---
df = simulate_peptide_data(spike_seq)
df.to_csv("spike_tcell_epitopes.csv", index=False)
print("CSV file 'spike_tcell_epitopes.csv' created with", len(df), "rows.")

!python generate_tcell_epitopes.py

from google.colab import files
files.download("spike_tcell_epitopes.csv")

script = '''
# (Paste your full script from earlier here, keep triple quotes intact)
'''

with open("generate_tcell_epitopes.py", "w") as f:
    f.write(script)

df = pd.read_csv("spike_tcell_epitopes.csv")

df.head()

"""# **Turn It Into a Web App** (Optional)
If you want a GUI or web-based app:

Use Streamlit or Gradio (simple Python web app tools)

Example (with Streamlit):
"""

!pip install streamlit

import streamlit as st
import pandas as pd
from Bio.SeqUtils.ProtParam import ProteinAnalysis
import random

st.title("T-cell Epitope Predictor")
sequence = st.text_area("Paste Protein Sequence", height=300)

if st.button("Generate Epitopes"):
    def generate_peptides(seq, length=9):
        return [(i + 1, i + length, seq[i:i + length]) for i in range(len(seq) - length + 1)]

    peptides = generate_peptides(sequence)
    rows = []
    for start, end, pep in peptides:
        analysis = ProteinAnalysis(pep)
        row = {
            "start_position": start,
            "end_position": end,
            "peptide_seq": pep,
            "isoelectric_point": round(analysis.isoelectric_point(), 2),
            "aromaticity": round(analysis.aromaticity(), 3),
            "hydrophobicity": round(analysis.gravy(), 3),
            "stability": round(analysis.instability_index(), 2)
        }
        rows.append(row)

    df = pd.DataFrame(rows)
    st.dataframe(df)
    st.download_button("Download CSV", df.to_csv(index=False), "epitopes.csv", "text/csv")
